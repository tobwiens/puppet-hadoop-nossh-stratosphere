# Set Users path
export PATH=$PATH:/bin:<%= scope.lookupvar('hadoop::params::java_home') %>/bin:<%= scope.lookupvar('hadoop::params::hadoop_base') %>/hadoop/bin

# Set Hadoop-related environment variables
export HADOOP_HOME=<%= scope.lookupvar('hadoop::params::hadoop_base') %>/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=<%= scope.lookupvar('hadoop::params::hadoop_conf') %>
export YARN_CONF_DIR=<%= scope.lookupvar('hadoop::params::yarn_conf') %>

# Set JAVA_HOME (we will also configure JAVA_HOME directly for Hadoop later on)
export JAVA_HOME=<%= scope.lookupvar('hadoop::params::java_home') %>

# Some convenient aliases and functions for running Hadoop-related commands
unalias fs &> /dev/null
alias fs="hadoop fs"
unalias hls &> /dev/null
alias hls="fs -ls"

# If you have LZO compression enabled in your Hadoop cluster and
# compress job outputs with LZOP (not covered in this tutorial):
# Conveniently inspect an LZOP compressed file from the command
# line; run via:
#
# $ lzohead /hdfs/path/to/lzop/compressed/file.lzo
#
# Requires installed 'lzop' command.
#
lzohead () {
    hadoop fs -cat $1 | lzop -dc | head -1000 | less
}
